#### 概况

用torchtext进行了初期的数据处理

模型主要使用CNN，embedding层、卷积层、池化层、先行层，参数都比较基本，没怎么调过

测试集准确率为89.17%

#### 初期数据处理

除空格切割于大小写转换外，利用正则表达式对一些英文常用的缩写词进行了分割，例如 's、've 等

#### 遇到的问题

##### 1. vocab混用

​	在测试结果的时候将测试集的数据加入到了vocab中，导致下标出现混乱，与训练时的结果不同

​	解决方案：先进行build_vocab操作，再构建测试集的dataset类，就不会混乱了

##### 2. 处理测试数据时漏添加label

​	由于测试集应该没有label，所以在创建测试数据dataset的时候没有加，实际上torchtext的dataset构建时数据要与fields统一，即使实际没有用到label

​	解决方案：加上任意标签即可

#### 模型参数

```python
batch_size = 500		# batch大小
kernel_sizes = [3,4,5]	# 每种卷积核大小
kernel_num = 50			# 每种卷积核数量
learning_rate = 0.001	# 学习率
epoch = 100				# 训练轮数
Embedding为随机的维度为100的词向量
```

#### 后期展望

1. 首先可以调整一下参数，观察是否能提高准确率
2. 可以尝试调节模型结构，例如添加一层bilstm之类